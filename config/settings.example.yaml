 # Note: etl/etl_map.py will use DATABASE_URL or POSTGRES_* from the environment if set.
# This db_url acts as a fallback.
db_url: postgresql://postgres:postgres@localhost:5432/iob_knowledge

ifc:
  schema_version: IFC4.3
  # Path to Samples file you added
  json_path: ./Samples/ifc_classes_with_psets.json
  # Use parent-chain context (class + ancestors) for IFC text when embedding/matching
  use_parent_context: true

uniclass:
  revision: 2025-09
  autodetect_revision: true
  enforce_monotonic_revision: true
  # Prefer this: auto-discover all .xlsx in folder
  xlsx_dir: ./Samples/uniclassTables
  # Or, alternatively, provide CSVs per facet (leave commented if not used)
  # csv_paths:
  #   EF: C:/path/to/Uniclass/EF.csv
  #   Ss: C:/path/to/Uniclass/Ss.csv
  #   Pr: C:/path/to/Uniclass/Pr.csv
  #   # add more facets as needed: TE, PM, Ac, En, SL, Ro, Co

output:
  dir: ./output
  viewer_json: ./output/viewer_mapping.json

matching:
  top_k: 10
  auto_accept_threshold: 0.70
  review_threshold: 0.55
  # weight for embedding similarity in final score (0..1). 0 disables blending
  embedding_weight: 0.25
  # number of nearest neighbors to consider from embeddings per IFC item
  embedding_top_k: 25


  anchor_bonus: 0.3
  anchor_use_ancestors: true
  # Convenience: list facets to skip entirely during matching
  skip_tables: [AC, CO, EF, EN, FI, MA, PC, PM, RK, RO, SL, ZZ, MA, TE]  # add more as needed e.g., [PC, FI, SL, ZZ] this setup only has PR and SS tables
  # Optional facet-aware rules to constrain candidates
  # - skip: true            -> ignore the entire facet
  # - abstract_only: true   -> allow only abstract IFC classes
  # - require_ifc_roots: [] -> require IFC to be a subclass of any of the listed roots
  rules:
    PR:
      require_ifc_roots: [IfcProduct]
    SS:
  require_ifc_roots: [IfcGroup, IfcSystem]
  disallow_prefixes: [IfcBuiltSystem]
    PM:
      require_ifc_roots: [IfcProcess]
    AC:
      require_ifc_roots: [IfcProcess]
  # basic synonym hints to boost lexical scoring
  synonyms:
    - ["hvac","mechanical services","building services"]
    - ["curtain wall","glazed facade","curtainwall"]
    - ["pipe","piping"]
    - ["duct","ductwork"]

embedding:
  model: mxbai-embed-large
  endpoint: http://localhost:11434
  batch_size: 16
  timeout_s: 30
  # 1024 for mxbai-embed-large and bge-m3; 768 for jina-embeddings-v2-base-en
  expected_dim: 1024
  # OpenAI-specific embedding model and expected dim when using --openai
  # e.g., text-embedding-3-small (1536) or text-embedding-3-large (3072)
  openai_model: text-embedding-3-small
  openai_expected_dim: 1536
  # pgvector ANN tuning
  ivf_lists: 128
  ivf_probes: 8 # between 5-8 (lower = faster, slightly lower recall)
  # query timeout for embedding neighbor search (milliseconds)
  query_timeout_ms: 5000

rerank:
  top_n: 0
  model: mistral:7b-instruct
  # OpenAI-specific chat model when using --openai (e.g., gpt-4o-mini)
  openai_model: gpt-4o-mini
  endpoint: http://localhost:11434
  temperature: 0
  max_tokens: 512
  fewshot_per_facet: 3
  timeout_s: 10

